{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model,ensemble,metrics,preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/richardknoche/Desktop/MainImages.csv')\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "#Randomize the data\n",
    "df = df.sample(frac=1,random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not using categoricals for now\n",
    "features = ['price','original_price','age', 'width', 'height',\n",
    "       'depth', 'Num_Images', 'Duration', \n",
    "       'default_angle', 'Thirds_Horizontal_Value_Sym', 'Salient_Hue',\n",
    "       'Complimentary_Color_Level', 'Thirds_To_Focal_Distance',\n",
    "       'Vertical_Hue_Sym', 'Laplacian_Sharpness', 'Salient_Value',\n",
    "       'Thirds_Horizontal_Saliency_Sym', 'Thirds_Value', 'Thirds_Sat',\n",
    "       'B_Mean', 'V_var', 'Thirds_Saliency', 'g_ygrad', 'Busyness',\n",
    "       'Horizontal_Saturation_Sym', 'Thirds_Vertical_Saliency_Sym', 'r_ygrad',\n",
    "       'B_Width', 'g_xgrad', 'G_Mean', 'g_xgrad_std',\n",
    "       'Thirds_Vertical_Hue_Sym', 'Thirds_Horizontal_Hue_Sym', 'Colorfulness',\n",
    "       'Vertical_Value_Sym', 'R_xgrad', 'Horizontal_Value_Sym',\n",
    "       'Salient_Saturation', 'standard_luminance', 'H_var',\n",
    "       'Thirds_Vertical_Value_Sym', 'Number_of_Contours',\n",
    "       'Thirds_Vertical_Saturation_Sym', 'R_Width', 'FFT_Sharpness',\n",
    "       'b_xgrad_std', 'V_mean', 'b_ygrad', 'R_Mean',\n",
    "       'Thirds_Horizontal_Saturation_Sym', 'b_xgrad', 'H_mean', 'r_ygrad_std',\n",
    "       'Histogram_Darkness', 'g_ygrad_std', 'Thirds_Hue', 'S_mean', 'S_var',\n",
    "       'G_Width', 'Lapacian_Saturation', 'percieved_luminace', 'b_ygrad_std',\n",
    "       'r_xgrad_std', 'Horizontal_Hue_Sym', 'Vertical_Saturation_Sym',\n",
    "       'Lapacian_Value', 'Lapacian_Hue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#top x%\n",
    "percentiles = [0.2,0.4,0.6,0.8,1.0]\n",
    "\n",
    "for percent in percentiles:\n",
    "    #Make CDF and figure out threshold for \"top_x_percent\"\n",
    "    count,edge,img = plt.hist(df['view_rate'],bins=np.linspace(0,0.001,500))\n",
    "    cdf = count.cumsum()/count.sum()\n",
    "    center = (edge[:-1]+edge[1:])/2\n",
    "    thresh_idx=len(cdf)-len(cdf[cdf> (1-percent)]) #Index of where top_x_percent starts in cdf\n",
    "    df['Top %0.1f Percentile' % (percent)] = df['view_rate']>center[thresh_idx] #Top x% of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'classifier_%s0' %(str(percent)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_roc = plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "fig_pr = plt.figure(2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR curve')\n",
    "\n",
    "for percent in percentiles:\n",
    "\n",
    "    col_to_predict = 'Top %0.1f Percentile' % (percent)\n",
    "\n",
    "    num_minority = min(len(df[df[col_to_predict]==False]),len(df[df[col_to_predict]==True]))\n",
    "    true_df = df[df[col_to_predict]==True]\n",
    "    false_df = df[df[col_to_predict]==False]\n",
    "\n",
    "    train_true = true_df.sample(n=int(np.floor(num_minority*0.6)),random_state = 102)\n",
    "    train_false = false_df.sample(n=int(np.floor(num_minority*0.6)),random_state = 102)\n",
    "\n",
    "    train = pd.concat([train_true,train_false])\n",
    "    test = df.drop(train.index)\n",
    "    \n",
    "    train_x = train[features]\n",
    "    train_y = train[col_to_predict]\n",
    "\n",
    "    test_x = test[features]\n",
    "    test_y = test[col_to_predict]\n",
    "    \n",
    "    #Normalize features\n",
    "    train_std_scale = preprocessing.StandardScaler().fit(train_x)\n",
    "    train_x_std = train_std_scale.transform(train_x)\n",
    "\n",
    "    train_minmax_scale = preprocessing.MinMaxScaler().fit(train_x)\n",
    "    train_x_minmax = train_minmax_scale.transform(train_x)\n",
    "\n",
    "    test_std_scale = preprocessing.StandardScaler().fit(test_x)\n",
    "    test_x_std = test_std_scale.transform(test_x)\n",
    "\n",
    "    test_minmax_scale = preprocessing.MinMaxScaler().fit(test_x)\n",
    "    test_x_minmax = test_minmax_scale.transform(test_x)\n",
    "\n",
    "    train_x_features = train_x_std\n",
    "    test_x_features = test_x_std\n",
    "\n",
    "    #Train Model\n",
    "    clf  = ensemble.RandomForestClassifier()\n",
    "    classifier_name = 'classifier_%s0' %(str(percent)[-1])\n",
    "    clf.fit(train_x_features,train_y)\n",
    "    exec('%s = clf' % (classifier_name))\n",
    "    predicted_y = clf.predict(test_x_features)\n",
    "    y_probs =clf.predict_proba(test_x_features)[:, 1]\n",
    "\n",
    "    #ROC\n",
    "    plt.figure(fig_roc.number)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y, y_probs)\n",
    "    plt.plot(fpr, tpr, label='Top %0.1f' % percent)\n",
    "\n",
    "\n",
    "    #Accuracy, Precision, Recall\n",
    "    print('Accuracy: ',clf.score(test_x_features,test_y))\n",
    "    f1score, tpr, thresholds = metrics.roc_curve(test_y, y_probs)\n",
    "\n",
    "    #Prec-Recall Curve\n",
    "    precision, recall, thresholds = precision_recall_curve(test_y,y_probs)\n",
    "    average_precision = average_precision_score(test_y, y_probs)\n",
    "    plt.figure(fig_pr.number)\n",
    "    plt.plot(recall, precision,label='RF')\n",
    "\n",
    "\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(test_y, predicted_y)\n",
    "    #classifier_metrics = pd.DataFrame( {'Precision' : precision, 'Recall' : recall, 'F-Score' : fscore, 'Support' : support})\n",
    "    #classifier_metrics\n",
    "\n",
    "legend_info = ['Coin Flip']+ [ 'Top %0.1f Classifier' % (i) for i in percentiles]\n",
    "plt.legend(legend_info[1:],loc=3)\n",
    "plt.figure(fig_roc.number)\n",
    "plt.legend(legend_info,loc=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CalcPrediction(row):\n",
    "    top_20 = classifier_20.predict(row.reshape(1,-1))\n",
    "    top_40 = classifier_40.predict(row.reshape(1,-1))\n",
    "    top_60 = classifier_60.predict(row.reshape(1,-1))\n",
    "    top_80 = classifier_80.predict(row.reshape(1,-1))\n",
    "    row['predicted_percentile'] = pd.Series([20,40,60,80])[[top_20[0],top_40[0],top_60[0],top_80[0]]].min()\n",
    "\n",
    "    \n",
    "#THIS GETS SCREWY HERE.. SINCE \"TEST_X\" CHANGES WITH EACH CLASSIFIER\n",
    "#WE COULD RUN THIS OVER EVERY ENTRY, BUT THEN SOME ENTRIES WERE TRAINED WITH THAT CLASSIFIER...\n",
    "test_x.apply(CalcPrediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize features\n",
    "train_x = preprocessing.normalize(train_x)\n",
    "test_x = preprocessing.normalize(test_x)\n",
    "\n",
    "#Train Model\n",
    "clf  = ensemble.RandomForestClassifier()\n",
    "clf.fit(train_x,train_y)\n",
    "predicted_y = clf.predict(test_x)\n",
    "y_probs =clf.predict_proba(test_x)[:, 1]\n",
    "\n",
    "#ROC\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, y_probs)\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Accuracy, Precision, Recall\n",
    "print('Accuracy: ',clf.score(test_x,test_y))\n",
    "f1score, tpr, thresholds = metrics.roc_curve(test_y, y_probs)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(test_y,y_probs)\n",
    "average_precision = average_precision_score(test_y, y_probs)\n",
    "print(average_precision)\n",
    "\n",
    "\n",
    "#Prec-Recall Curve\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [1, 1], 'k--')\n",
    "plt.plot(recall, precision,label='RF')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "precision, recall, fscore, support = metrics.precision_recall_fscore_support(test_y, predicted_y)\n",
    "classifier_metrics = pd.DataFrame( {'Precision' : precision, 'Recall' : recall, 'F-Score' : fscore, 'Support' : support})\n",
    "classifier_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "rankings = []\n",
    "for idx in range(len(features)):\n",
    "    rankings.append(importances[indices[idx]])\n",
    "    print(\"%d. %s %f\" % (idx + 1, features[idx], importances[indices[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(features)), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(len(features)))\n",
    "ax=plt.gca()\n",
    "ax.set_xticklabels([features for (ranks,features) in sorted(zip(rankings,features),reverse=True)],rotation=90)\n",
    "plt.xlim([-1, len(features)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
