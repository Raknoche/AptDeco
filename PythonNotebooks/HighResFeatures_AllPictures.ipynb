{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to build a dataframe of image features.\n",
    "\n",
    "\n",
    "Listing features are extracted from AptDecos MySQL database.\n",
    "\n",
    "\n",
    "Image features are extracted from image urls, using the ImageFeatures library that was created for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import urllib\n",
    "import cv2\n",
    "from ImageFeatures import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://raknoche:localpswd@localhost/AptDeco\")\n",
    "\n",
    "\n",
    "ProductImages = pd.read_sql(\"SELECT * FROM ProductImages\",engine)\n",
    "ProductPopularity = pd.read_sql('SELECT * FROM ProductPopularity;',engine)\n",
    "ProductsTable = pd.read_sql('SELECT * FROM ProductsTable;',engine)\n",
    "ProductsTable.rename(columns={'id':'product_id'}, inplace=True)\n",
    "OrderItems = pd.read_sql('SELECT * FROM OrderItems;',engine)\n",
    "\n",
    "#Maximum timestamp in the dataset\n",
    "max_timestamp = np.array(OrderItems['created_at'].tolist()+ProductsTable['created_at'].tolist()).max()\n",
    "min_timestamp = ProductsTable.merge(ProductPopularity,how='inner',on='product_id')['created_at'].min()\n",
    "\n",
    "#Add some info about expirations to ProductsTable\n",
    "ProductsTable['HasExpired'] = (ProductsTable['expire_at'] < max_timestamp )\n",
    "\n",
    "#Add info about whether the product sold or not\n",
    "ProductsTable['HasSold'] = ProductsTable.apply(lambda row: row['product_id'] in OrderItems['product_id'].values,axis=1)\n",
    "\n",
    "#Add info about when the items sold\n",
    "temp_df=ProductsTable[ProductsTable['HasSold']==True].merge(OrderItems, how='left', on='product_id')[['product_id','created_at_y']]\n",
    "temp_df.rename(columns={'created_at_y':'sold_at'}, inplace=True)\n",
    "\n",
    "ProductsTable=ProductsTable.merge(temp_df.groupby('product_id').max().reset_index(), how='outer', on='product_id')\n",
    "\n",
    "#Drop user_id is NULL\n",
    "ProductsTable=ProductsTable[ProductsTable['user_id'].notnull()]\n",
    "\n",
    "#Drop products that were created after PopularityTable was\n",
    "ProductsTable=ProductsTable[ProductsTable['created_at'] >= min_timestamp]\n",
    "\n",
    "#Combine the ProductTable and ProductPopularity tables\n",
    "count_table=ProductsTable.merge(ProductPopularity, how='outer', on='product_id' )\\\n",
    "    [['product_id','type','count','is_approved','is_published','HasSold','HasExpired','sold_at','expire_at','created_at',\\\n",
    "     'price','original_price','age','width','height','depth','category_id','condition','material_id','color_id']]\n",
    "    \n",
    "#Get Number of images feature\n",
    "temp=count_table.merge(ProductImages, how = 'outer', on='product_id' )\n",
    "temp = temp.groupby('product_id').count().reset_index()[['product_id','path']]\n",
    "temp.columns=['product_id','Num_Images']\n",
    "count_table = count_table.merge(temp, how='outer', on='product_id')\n",
    "\n",
    "#Make a table of how many views each product has, assuming zero if it isn't in ProductPopularity\n",
    "currently_listed = (count_table['is_approved']==True) & (count_table['is_published']==True)\n",
    "already_sold = (count_table['is_approved']==True) & (count_table['HasSold']==True)\n",
    "already_expired = (count_table['is_approved']==True) & (count_table['HasExpired']==True)\n",
    "\n",
    "clean_listings_cut = currently_listed | already_sold | already_expired\n",
    "\n",
    "view_numbers_cut = ((count_table['type']=='view') | (count_table['type'].isnull()))\n",
    "\n",
    "views_table = count_table[ clean_listings_cut  & view_numbers_cut].fillna(0)\n",
    "\n",
    "views_table['Duration'] = [None]*len(views_table)\n",
    "\n",
    "#Get listing lengths\n",
    "sold_cut = views_table['HasSold']==True\n",
    "views_table.ix[sold_cut,'Duration'] = views_table[sold_cut]['sold_at']-views_table[sold_cut]['created_at']\n",
    "\n",
    "expired_cut = (views_table['HasSold']==False) & (views_table['HasExpired']==True)\n",
    "views_table.ix[expired_cut,'Duration'] = views_table[expired_cut]['expire_at']-views_table[expired_cut]['created_at']\n",
    "\n",
    "still_listed_cut = (views_table['HasSold']==False) & (views_table['HasExpired']==False)\n",
    "views_table.ix[still_listed_cut,'Duration'] = max_timestamp-views_table[still_listed_cut]['created_at']\n",
    "\n",
    "#remove listing lengths less than zero\n",
    "views_table=views_table[views_table['Duration']>0]\n",
    "\n",
    "#Views per unit time\n",
    "views_table['view_rate']=views_table['count']/views_table['Duration']\n",
    "\n",
    "#Create a \"WasViewed\" column, and drop uneeded columns\n",
    "cleaned_table = views_table.drop(['type','is_approved','is_published'],axis=1)\n",
    "cleaned_table['WasViewed']=cleaned_table['count']>0\n",
    "\n",
    "#Get the \"main\" image for each product, drop anything that we don't have a picture for\n",
    "main_images = cleaned_table.merge(ProductImages, how='inner', on='product_id')\\\n",
    "    .drop(['id','is_locked','is_visible','s3_path','90_exists','180_exists','270_exists','is_uploaded','description'],axis=1)\n",
    "\n",
    "#Remove the images that don't have actual urls\n",
    "main_images = main_images[ main_images['path'].str.contains(\"https:\")].reset_index(drop=True)\n",
    "\n",
    "\n",
    "main_images.sort_index(ascending=False,inplace=True)\n",
    "main_images.reset_index(drop=True,inplace=True)\n",
    "main_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change paths to high-res photos\n",
    "def ChangePaths(row):\n",
    "    return row['path'].replace('200-200-crop','1500-1500-frame')\n",
    "\n",
    "main_images['path']=main_images.apply(ChangePaths,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomize the order, and save the base df\n",
    "main_images=main_images.sample(frac=1,random_state=102)\n",
    "main_images.to_csv('base_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all of the image feautres\n",
    "for idx in range(0,len(main_images)):\n",
    "    try:\n",
    "        #Image Features\n",
    "        image = UrlToImage(main_images.ix[idx,'path'])\n",
    "        image = CropImage(image)\n",
    "        \n",
    "        features=ExtractFeatures(image)\n",
    "\n",
    "        for key in features.keys():\n",
    "            main_images.loc[idx,key] = features[key]\n",
    "            \n",
    "    except:\n",
    "        print(\"Problem with grabbing image\")\n",
    "        \n",
    "    #Save every 2000 images process (~30 minutes)\n",
    "    if (idx % 2000 == 0):\n",
    "        main_images.to_csv('HighRes_ImageFeatures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
