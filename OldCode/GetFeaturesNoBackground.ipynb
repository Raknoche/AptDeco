{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/richardknoche/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pycircstat.descriptive as circstat\n",
    "import pySaliencyMap as SMap\n",
    "import itertools\n",
    "from skimage import data\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcSymmetry(src,mask=None):\n",
    "    a = src.astype(\"float\")\n",
    "    b1 = src[::-1,:].astype(\"float\") #Flip upsidedown\n",
    "    b2 = src[:,::-1].astype(\"float\") #Flip left/right\n",
    "\n",
    "    #Calculate symmetry by multplying mirrored images\n",
    "    fs = (a + b2)/2\n",
    "    fa = (a - b2)/2\n",
    "    if type(mask) == np.ndarray:\n",
    "        Sym_Horizontal_Value = (fs[mask==1]**2).sum()/((fs[mask==1]**2).sum() + (fa[mask==1]**2).sum())\n",
    "    else:\n",
    "        Sym_Horizontal_Value = (fs**2).sum()/((fs**2).sum() + (fa**2).sum())\n",
    "\n",
    "    fs = (a + b1)/2\n",
    "    fa = (a - b1)/2\n",
    "    if type(mask) == np.ndarray:\n",
    "        Sym_Vertical_Value = (fs[mask==1]**2).sum()/( (fs[mask==1]**2).sum() + (fa[mask==1]**2).sum())\n",
    "    else:\n",
    "        Sym_Vertical_Value = (fs**2).sum()/( (fs**2).sum() + (fa**2).sum())\n",
    "\n",
    "    #Instead of 0.5-1, scale from 0-1\n",
    "    Sym_Horizontal_Value=Sym_Horizontal_Value*2 - 1\n",
    "    Sym_Vertical_Value=Sym_Vertical_Value*2 - 1\n",
    "\n",
    "    return(Sym_Horizontal_Value,Sym_Vertical_Value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ExtractFeatures(file):\n",
    "\n",
    "    features={}\n",
    "\n",
    "    # Load Image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    '''Image Shape Features'''\n",
    "    features['Aspect_Ratio'] = float(image.shape[0])/image.shape[1]\n",
    "    features['Image_Size'] = image.size/3 #Divide by three for RGB\n",
    "\n",
    "\n",
    "    #Resize image -- DONT DO THIS IF THEY ARE ALL 200x200\n",
    "    scaler = np.min([800.0/image.shape[0], 800.0/image.shape[1]])\n",
    "    image = cv2.resize(image,(np.int(scaler*image.shape[1]),np.int(scaler*image.shape[0])),interpolation=cv2.INTER_AREA)\n",
    "    I_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    #Find contour\n",
    "    ret3,thresh = cv2.threshold(cv2.GaussianBlur(I_gray,(5,5),30),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    thresh=cv2.bitwise_not(thresh)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "\n",
    "    cXs=np.array([])\n",
    "    cYs=np.array([])\n",
    "    \n",
    "    #mask to select within contour bounds\n",
    "    mask = thresh.astype(bool)\n",
    "    \n",
    "    #Arrays for contour features\n",
    "    areas = np.array([]) #fraction of image occupied by object\n",
    "    widths = np.array([]) #item widths (normalized to image width)\n",
    "    heights = np.array([]) #item heights (normalized to image height)\n",
    "    extents = np.array([]) #fraction of rectangular bounding box that is occupied\n",
    "    left_weights = np.array([]) #(x_center - x_min)/width -- how left heavy is it\n",
    "    top_weights = np.array([]) #(y_center - y_min)/height -- how top heavy is it\n",
    "    aspect_ratios = np.array([]) #ratio of width to height\n",
    "    solidities = np.array([]) #How \"solid\" the object is\n",
    "    \n",
    "    for c in cnts:\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        if  M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            #contour properties\n",
    "            area = cv2.contourArea(c)\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            rect_area = w*h\n",
    "            hull = cv2.convexHull(c)\n",
    "            hull_area = cv2.contourArea(hull)\n",
    "\n",
    "            #Furniture Features\n",
    "            areas = np.append(areas,float(area))\n",
    "            extents = np.append(extents,float(area)/rect_area)\n",
    "            widths = np.append(widths,float(w)/image.shape[1])\n",
    "            heights =np.append(heights,float(h)/image.shape[0])\n",
    "            left_weights = np.append(left_weights, (cX - x)/w)\n",
    "            top_weights = np.append(top_weights, (cY - y)/w)\n",
    "            aspect_ratios = np.append(aspect_ratios, float(w)/h)\n",
    "            solidities = np.append(solidities,float(area)/hull_area)\n",
    "            cXs = np.append(cXs,int(M[\"m10\"] / M[\"m00\"]))\n",
    "            cYs = np.append(cYs,int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "    #Full area of the contours\n",
    "    features['Fractional_Contour_Area'] = areas.sum()/thresh.size\n",
    "   \n",
    "    #Image dimensions\n",
    "    half_xl = np.floor(thresh.shape[1]/2)\n",
    "    half_yl = np.floor(thresh.shape[0]/2)\n",
    "\n",
    "    features['Centroid_XOffset'] = (cX-half_xl)/(half_xl*2)\n",
    "    features['Centroid_YOffset'] = (cY-half_yl)/(half_yl*2)\n",
    "    features['Centroid_to_Center_Distance'] = (((cY-half_yl)/(half_yl*2))**2 + ((cX-half_xl)/(half_xl*2))**2)**(1/2)\n",
    "    features['Fractional_BB_Contour_Area'] = extents.mean()\n",
    "    features['Contour_Solidity'] = solidities.mean()\n",
    "    features['Contour_Width'] = widths.mean()\n",
    "    features['Contour_Height'] = heights.mean()\n",
    "     \n",
    "            \n",
    "    \n",
    "    #Extract color spaces\n",
    "    b=image[:,:,0]\n",
    "    g=image[:,:,1]\n",
    "    r=image[:,:,2]\n",
    "\n",
    "\n",
    "    I_hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    I_h = I_hsv[:,:,0]\n",
    "    I_s = I_hsv[:,:,1]\n",
    "    I_v = I_hsv[:,:,2]\n",
    "    I_h_rad = I_h*np.pi/180.0 #Hue converted to radians\n",
    "\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel,a_channel,b_channel = cv2.split(lab_image)\n",
    "\n",
    "\n",
    "    '''Sharpness features'''\n",
    "    #Feature 1\n",
    "    laplacian = cv2.Laplacian(I_gray, cv2.CV_64F)\n",
    "    features['Laplacian_Sharpness']= laplacian[mask==1].var()\n",
    "\n",
    "    #Feature 2\n",
    "    rows, cols = I_gray.shape\n",
    "    crow, ccol = int(rows/2),int(cols/2)\n",
    "    f = np.fft.fft2(I_gray)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift[crow-75:crow+75, ccol-75:ccol+75] = 0\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_fft = np.fft.ifft2(f_ishift)\n",
    "    img_fft = 20*np.log(np.abs(img_fft))\n",
    "    features['FFT_Sharpness'] = np.mean(img_fft[mask==1])\n",
    "\n",
    "\n",
    "    '''Color Features'''\n",
    "    #Feature 4 - Is it gray\n",
    "    features['IsGray'] = np.all(I_s[mask==1]==0)\n",
    "\n",
    "    #Feature X -- How colorful is it\n",
    "    mu_ab = np.sqrt( a_channel[mask==1].mean()**2 + b_channel[mask==1].mean()**2)\n",
    "    features['Colorfulness'] = a_channel[mask==1].std() + b_channel[mask==1].std() + 0.39*mu_ab\n",
    "\n",
    "\n",
    "    #Feature 5-10 - Avg and normalized standard deviation of each color channel\n",
    "    features['B_Mean'] = b[mask==1].mean()\n",
    "    features['G_Mean'] = g[mask==1].mean()\n",
    "    features['R_Mean'] = r[mask==1].mean()\n",
    "    features['B_Width'] = b[mask==1].std()/features['B_Mean']\n",
    "    features['G_Width'] = g[mask==1].std()/features['G_Mean']\n",
    "    features['R_Width'] = r[mask==1].std()/features['R_Mean']\n",
    "\n",
    "    #Feature 11-22 - Mean and standard deviation of color gradients in each channel\n",
    "    features['R_xgrad'] = np.mean(cv2.Sobel(r,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "    features['g_xgrad']= np.mean(cv2.Sobel(g,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "    features['b_xgrad'] = np.mean(cv2.Sobel(b,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "\n",
    "    features['r_ygrad'] = np.mean(cv2.Sobel(r,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "    features['g_ygrad'] = np.mean(cv2.Sobel(g,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "    features['b_ygrad'] = np.mean(cv2.Sobel(b,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "\n",
    "    features['r_xgrad_std'] = np.std(cv2.Sobel(r,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "    features['g_xgrad_std'] = np.std(cv2.Sobel(g,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "    features['b_xgrad_std'] = np.std(cv2.Sobel(b,cv2.CV_64F,1,0,ksize=1)[mask==1])\n",
    "\n",
    "    features['r_ygrad_std'] = np.std(cv2.Sobel(r,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "    features['g_ygrad_std'] = np.std(cv2.Sobel(g,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "    features['b_ygrad_std'] = np.std(cv2.Sobel(b,cv2.CV_64F,0,1,ksize=1)[mask==1])\n",
    "\n",
    "    #Feautres XX - HSV characteristic\n",
    "    features['H_mean'] = circstat.mean(I_h_rad[mask==1])*180.0/np.pi           \n",
    "    features['H_var']  = circstat.var(I_h_rad[mask==1])*180.0/np.pi\n",
    "\n",
    "    features['S_mean'] = np.mean(I_s[mask==1])/255.0                           \n",
    "    features['S_var']  = np.var(I_s[mask==1]/255.0)\n",
    "\n",
    "    features['V_mean'] = np.mean(I_v[mask==1])/255.0                           \n",
    "    features['V_var']  = np.var(I_v[mask==1]/255.0)\n",
    "\n",
    "    features['Lapacian_Hue'] = cv2.Laplacian(I_h/255.0, cv2.CV_64F)[mask==1].var()\n",
    "    features['Lapacian_Saturation'] = cv2.Laplacian(I_s/255.0, cv2.CV_64F)[mask==1].var()\n",
    "    features['Lapacian_Value']     = cv2.Laplacian(I_v/255.0, cv2.CV_64F)[mask==1].var()\n",
    "\n",
    "    #Feature XX -- complementary colors\n",
    "    features['Complimentary_Color_Level'] = np.abs(np.exp(2*I_h_rad[mask==1]*1j).sum() / len(I_h[mask==1].flatten())) #ranges from 0 to 1, 1 is more complementary\n",
    "\n",
    "\n",
    "    '''Darkness Features'''\n",
    "    #Feature 3\n",
    "    img_hist = cv2.calcHist([image[mask==1]],[0],None,[256],[0,256])\n",
    "    features['Histogram_Darkness'] = img_hist.mean()\n",
    "\n",
    "    #Feature -- Contrast level (takes too long.. goes from 0.3 -> 1.2 seconds)\n",
    "    #entr_img = entropy(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), disk(7))\n",
    "    #features['Contrast']=entr_img[mask==1].max()\n",
    "\n",
    "    #Feature \n",
    "    features['standard_luminance'] = (0.2126*features['R_Mean'] + 0.7152*features['G_Mean'] + 0.0722*features['B_Mean'])\n",
    "    features['percieved_luminace'] = (0.299*features['R_Mean'] + 0.587*features['G_Mean'] + 0.114*features['B_Mean'])\n",
    "\n",
    "\n",
    "    '''Focal Point Features'''\n",
    "    sm = SMap.pySaliencyMap(image.shape[1], image.shape[0])\n",
    "    saliencymap    = sm.SMGetSM(image)\n",
    "\n",
    "    #Features XX -- HSV at high saliency focal points, compared to image average\n",
    "    Saliency_Thresh = 0.2\n",
    "    features['Salient_Hue'] = np.log(circstat.mean(I_h[saliencymap>=Saliency_Thresh]*np.pi/180.0)/circstat.mean(I_h*np.pi/180.0))\n",
    "    features['Salient_Saturation'] = np.log(np.mean(I_s[saliencymap>=Saliency_Thresh])/np.mean(I_s))\n",
    "    features['Salient_Value'] = np.log(np.mean(I_v[saliencymap>=Saliency_Thresh])/np.mean(I_v))\n",
    "\n",
    "\n",
    "    '''Rule of Thirds Features'''\n",
    "    #Get number of row and columns\n",
    "    nrows = image.shape[0]\n",
    "    ncols = image.shape[1]\n",
    "\n",
    "    #Get 1/3rd and 2/3rd row and columns\n",
    "    first_thrd_rows = np.int(np.floor(nrows*1.0/3.0))\n",
    "    second_thrd_rows = np.int(np.floor(nrows*2.0/3.0))\n",
    "    first_thrd_cols = np.int(np.floor(ncols*1.0/3.0))\n",
    "    second_thrd_cols = np.int(np.floor(ncols*2.0/3.0))\n",
    "\n",
    "    #Define areas that are \"close\" to 1/3rd lines\n",
    "    margin = 20.0\n",
    "    above_first_thrd_rows = np.int(first_thrd_rows - np.floor(nrows/margin))\n",
    "    below_first_thrd_rows = np.int(first_thrd_rows + np.floor(nrows/margin))\n",
    "\n",
    "    above_second_thrd_rows = np.int(second_thrd_rows - np.floor(nrows/margin)) #_i\n",
    "    below_second_thrd_rows = np.int(second_thrd_rows + np.floor(nrows/margin)) #_o\n",
    "\n",
    "    left_first_thrd_cols = np.int(first_thrd_cols - np.floor(ncols/margin))\n",
    "    right_first_thrd_cols = np.int(first_thrd_cols + np.floor(ncols/margin))\n",
    "\n",
    "    left_second_thrd_cols = np.int(second_thrd_cols - np.floor(ncols/margin))\n",
    "    right_second_thrd_cols = np.int(second_thrd_cols + np.floor(ncols/margin))\n",
    "\n",
    "    #Build mask of where center of thirds are\n",
    "    thrds_mask = np.zeros_like(I_h)\n",
    "    thrds_mask[above_first_thrd_rows:below_second_thrd_rows,left_first_thrd_cols:right_second_thrd_cols] = 1\n",
    "    thrds_mask[below_first_thrd_rows:above_second_thrd_rows,right_first_thrd_cols:left_second_thrd_cols] = 0\n",
    "\n",
    "    #HSV and Saliency of the thirds lines\n",
    "    features['Thirds_Hue']      = circstat.mean(I_h[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]*np.pi/180.0)*180.0/np.pi \n",
    "    features['Thirds_Sat']      = np.mean(I_s[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]/255.0)                         \n",
    "    features['Thirds_Value']    = np.mean(I_v[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]/255.0)                         \n",
    "    features['Thirds_Saliency'] = np.sum(saliencymap[thrds_mask==1])/np.sum(thrds_mask)\n",
    "\n",
    "    #How far is the maximum focal point from the thirds intersections\n",
    "    (maxs_y,maxs_x) = np.where(saliencymap == np.max(saliencymap))\n",
    "    t_rows = [first_thrd_rows,second_thrd_rows]\n",
    "    t_cols = [first_thrd_cols,second_thrd_cols]\n",
    "    thrds_coords = list(itertools.product(t_rows, t_cols))\n",
    "    features['Thirds_To_Focal_Distance']= np.min([np.sqrt(((maxs_x[0] - thrds[1])/np.float(ncols))**2 + ((maxs_y[0] - thrds[0])/np.float(nrows))**2) for thrds in thrds_coords]) / np.sqrt(2)\n",
    "\n",
    "    '''Symmetry Features'''\n",
    "    features['Horizontal_Hue_Sym'],features['Vertical_Hue_Sym'] = CalcSymmetry(I_h)\n",
    "    features['Horizontal_Saturation_Sym'],features['Vertical_Saturation_Sym'] = CalcSymmetry(I_s)\n",
    "    features['Horizontal_Value_Sym'],features['Vertical_Value_Sym'] = CalcSymmetry(I_v)\n",
    "\n",
    "    features['Thirds_Horizontal_Hue_Sym'],features['Thirds_Vertical_Hue_Sym'] = CalcSymmetry(I_h,thrds_mask)\n",
    "    features['Thirds_Horizontal_Saturation_Sym'],features['Thirds_Vertical_Saturation_Sym'] = CalcSymmetry(I_s,thrds_mask)\n",
    "    features['Thirds_Horizontal_Value_Sym'],features['Thirds_Vertical_Value_Sym'] = CalcSymmetry(I_v,thrds_mask)\n",
    "    features['Thirds_Horizontal_Saliency_Sym'],features['Thirds_Vertical_Saliency_Sym'] = CalcSymmetry(saliencymap,thrds_mask)\n",
    "\n",
    "    ''' Image Busyness '''\n",
    "    features['Busyness'] = ( (cXs.std()/cXs.mean())**2 + (cYs.std()/cYs.mean())**2)**(1/2)  \n",
    "    features['Number_of_Contours'] = len(cnts)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3551149368286133\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0=time.time()\n",
    "file = '/Users/richardknoche/Desktop/TestImages/Blur/Blurry/Couch4.jpg'\n",
    "features = ExtractFeatures(file)\n",
    "t1=time.time()\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
