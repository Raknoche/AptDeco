{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pycircstat.descriptive as circstat\n",
    "import pySaliencyMap as SMap\n",
    "import itertools\n",
    "from skimage import data\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcSymmetry(src,mask=None):\n",
    "    a = src.astype(\"float\")\n",
    "    b1 = src[::-1,:].astype(\"float\") #Flip upsidedown\n",
    "    b2 = src[:,::-1].astype(\"float\") #Flip left/right\n",
    "\n",
    "    #Calculate symmetry by multplying mirrored images\n",
    "    fs = (a + b2)/2\n",
    "    fa = (a - b2)/2\n",
    "    if type(mask) == np.ndarray:\n",
    "        Sym_Horizontal_Value = (fs[mask==1]**2).sum()/((fs[mask==1]**2).sum() + (fa[mask==1]**2).sum())\n",
    "    else:\n",
    "        Sym_Horizontal_Value = (fs**2).sum()/((fs**2).sum() + (fa**2).sum())\n",
    "\n",
    "    fs = (a + b1)/2\n",
    "    fa = (a - b1)/2\n",
    "    if type(mask) == np.ndarray:\n",
    "        Sym_Vertical_Value = (fs[mask==1]**2).sum()/( (fs[mask==1]**2).sum() + (fa[mask==1]**2).sum())\n",
    "    else:\n",
    "        Sym_Vertical_Value = (fs**2).sum()/( (fs**2).sum() + (fa**2).sum())\n",
    "\n",
    "    #Instead of 0.5-1, scale from 0-1\n",
    "    Sym_Horizontal_Value=Sym_Horizontal_Value*2 - 1\n",
    "    Sym_Vertical_Value=Sym_Vertical_Value*2 - 1\n",
    "\n",
    "    return(Sym_Horizontal_Value,Sym_Vertical_Value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ExtractFeatures(file):\n",
    "\n",
    "    features={}\n",
    "\n",
    "    # Load Image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    '''Image Shape Features'''\n",
    "    features['Aspect_Ratio'] = float(image.shape[0])/image.shape[1]\n",
    "    features['Image_Size'] = image.size/3 #Divide by three for RGB\n",
    "\n",
    "\n",
    "    #Resize image\n",
    "    scaler = np.min([800.0/image.shape[0], 800.0/image.shape[1]])\n",
    "    image = cv2.resize(image,(np.int(scaler*image.shape[1]),np.int(scaler*image.shape[0])),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    #Extract color spaces\n",
    "    b=image[:,:,0]\n",
    "    g=image[:,:,1]\n",
    "    r=image[:,:,2]\n",
    "\n",
    "    I_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    I_hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    I_h = I_hsv[:,:,0]\n",
    "    I_s = I_hsv[:,:,1]\n",
    "    I_v = I_hsv[:,:,2]\n",
    "    I_h_rad = I_h.flatten()*np.pi/180.0 #Hue converted to radians\n",
    "\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel,a_channel,b_channel = cv2.split(lab_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''Sharpness features'''\n",
    "    #Feature 1\n",
    "    laplacian = cv2.Laplacian(I_gray, cv2.CV_64F)\n",
    "    features['Laplacian_Sharpness']= laplacian.var()\n",
    "\n",
    "    #Feature 2\n",
    "    rows, cols = I_gray.shape\n",
    "    crow, ccol = int(rows/2),int(cols/2)\n",
    "    f = np.fft.fft2(I_gray)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift[crow-75:crow+75, ccol-75:ccol+75] = 0\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_fft = np.fft.ifft2(f_ishift)\n",
    "    img_fft = 20*np.log(np.abs(img_fft))\n",
    "    features['FFT_Sharpness'] = np.mean(img_fft)\n",
    "\n",
    "\n",
    "    '''Color Features'''\n",
    "    #Feature 4 - Is it gray\n",
    "    features['IsGray'] = np.all(I_s==0)\n",
    "\n",
    "    #Feature X -- How colorful is it\n",
    "    mu_ab = np.sqrt( a_channel.mean()**2 + b_channel.mean()**2)\n",
    "    features['Colorfulness'] = a_channel.std() + b_channel.std() + 0.39*mu_ab\n",
    "\n",
    "\n",
    "    #Feature 5-10 - Avg and normalized standard deviation of each color channel\n",
    "    (rgb_means, rgb_stds) = cv2.meanStdDev(image)\n",
    "    features['B_Mean'],features['G_Mean'],features['R_Mean']=rgb_means[:,0]\n",
    "    features['B_Width'],features['G_Width'],features['R_Width']=rgb_stds[:,0]/rgb_means[:,0]\n",
    "\n",
    "    #Feature 11-22 - Mean and standard deviation of color gradients in each channel\n",
    "    features['R_xgrad'] = np.mean(cv2.Sobel(r,cv2.CV_64F,1,0,ksize=1))\n",
    "    features['g_xgrad']= np.mean(cv2.Sobel(g,cv2.CV_64F,1,0,ksize=1))\n",
    "    features['b_xgrad'] = np.mean(cv2.Sobel(b,cv2.CV_64F,1,0,ksize=1))\n",
    "\n",
    "    features['r_ygrad'] = np.mean(cv2.Sobel(r,cv2.CV_64F,0,1,ksize=1))\n",
    "    features['g_ygrad'] = np.mean(cv2.Sobel(g,cv2.CV_64F,0,1,ksize=1))\n",
    "    features['b_ygrad'] = np.mean(cv2.Sobel(b,cv2.CV_64F,0,1,ksize=1))\n",
    "\n",
    "    features['r_xgrad_std'] = np.std(cv2.Sobel(r,cv2.CV_64F,1,0,ksize=1))\n",
    "    features['g_xgrad_std'] = np.std(cv2.Sobel(g,cv2.CV_64F,1,0,ksize=1))\n",
    "    features['b_xgrad_std'] = np.std(cv2.Sobel(b,cv2.CV_64F,1,0,ksize=1))\n",
    "\n",
    "    features['r_ygrad_std'] = np.std(cv2.Sobel(r,cv2.CV_64F,0,1,ksize=1))\n",
    "    features['g_ygrad_std'] = np.std(cv2.Sobel(g,cv2.CV_64F,0,1,ksize=1))\n",
    "    features['b_ygrad_std'] = np.std(cv2.Sobel(b,cv2.CV_64F,0,1,ksize=1))\n",
    "\n",
    "    #Feautres XX - HSV characteristic\n",
    "    features['H_mean'] = circstat.mean(I_h_rad)*180.0/np.pi           \n",
    "    features['H_var']  = circstat.var(I_h_rad)*180.0/np.pi\n",
    "\n",
    "    features['S_mean'] = np.mean(I_s)/255.0                           \n",
    "    features['S_var']  = np.var(I_s/255.0)\n",
    "\n",
    "    features['V_mean'] = np.mean(I_v)/255.0                           \n",
    "    features['V_var']  = np.var(I_v/255.0)\n",
    "\n",
    "    features['Lapacian_Hue'] = cv2.Laplacian(I_h/255.0, cv2.CV_64F).var()\n",
    "    features['Lapacian_Saturation'] = cv2.Laplacian(I_s/255.0, cv2.CV_64F).var()\n",
    "    features['Lapacian_Value']     = cv2.Laplacian(I_v/255.0, cv2.CV_64F).var()\n",
    "\n",
    "    #Feature XX -- complementary colors\n",
    "    features['Complimentary_Color_Level'] = np.abs(np.exp(2*I_h_rad*1j).sum() / len(I_h.flatten())) #ranges from 0 to 1, 1 is more complementary\n",
    "\n",
    "\n",
    "    '''Darkness Features'''\n",
    "    #Feature 3\n",
    "    img_hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "    features['Histogram_Darkness'] = img_hist.mean()\n",
    "\n",
    "    #Feature -- Contrast level (takes too long.. goes from 0.3 -> 1.2 seconds)\n",
    "    #entr_img = entropy(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), disk(7))\n",
    "    #features['Contrast']=entr_img.max()\n",
    "\n",
    "    #Feature \n",
    "    features['standard_luminance'] = (0.2126*features['R_Mean'] + 0.7152*features['G_Mean'] + 0.0722*features['B_Mean'])\n",
    "    features['percieved_luminace'] = (0.299*features['R_Mean'] + 0.587*features['G_Mean'] + 0.114*features['B_Mean'])\n",
    "\n",
    "\n",
    "    '''Focal Point Features'''\n",
    "    sm = SMap.pySaliencyMap(image.shape[1], image.shape[0])\n",
    "    saliencymap    = sm.SMGetSM(image)\n",
    "\n",
    "    #Features XX -- HSV at high saliency focal points, compared to image average\n",
    "    Saliency_Thresh = 0.2\n",
    "    features['Salient_Hue'] = np.log(circstat.mean(I_h[saliencymap>=Saliency_Thresh]*np.pi/180.0)/circstat.mean(I_h*np.pi/180.0))\n",
    "    features['Salient_Saturation'] = np.log(np.mean(I_s[saliencymap>=Saliency_Thresh])/np.mean(I_s))\n",
    "    features['Salient_Value'] = np.log(np.mean(I_v[saliencymap>=Saliency_Thresh])/np.mean(I_v))\n",
    "\n",
    "\n",
    "    '''Rule of Thirds Features'''\n",
    "    #Get number of row and columns\n",
    "    nrows = image.shape[0]\n",
    "    ncols = image.shape[1]\n",
    "\n",
    "    #Get 1/3rd and 2/3rd row and columns\n",
    "    first_thrd_rows = np.int(np.floor(nrows*1.0/3.0))\n",
    "    second_thrd_rows = np.int(np.floor(nrows*2.0/3.0))\n",
    "    first_thrd_cols = np.int(np.floor(ncols*1.0/3.0))\n",
    "    second_thrd_cols = np.int(np.floor(ncols*2.0/3.0))\n",
    "\n",
    "    #Define areas that are \"close\" to 1/3rd lines\n",
    "    margin = 20.0\n",
    "    above_first_thrd_rows = np.int(first_thrd_rows - np.floor(nrows/margin))\n",
    "    below_first_thrd_rows = np.int(first_thrd_rows + np.floor(nrows/margin))\n",
    "\n",
    "    above_second_thrd_rows = np.int(second_thrd_rows - np.floor(nrows/margin)) #_i\n",
    "    below_second_thrd_rows = np.int(second_thrd_rows + np.floor(nrows/margin)) #_o\n",
    "\n",
    "    left_first_thrd_cols = np.int(first_thrd_cols - np.floor(ncols/margin))\n",
    "    right_first_thrd_cols = np.int(first_thrd_cols + np.floor(ncols/margin))\n",
    "\n",
    "    left_second_thrd_cols = np.int(second_thrd_cols - np.floor(ncols/margin))\n",
    "    right_second_thrd_cols = np.int(second_thrd_cols + np.floor(ncols/margin))\n",
    "\n",
    "    #Build mask of where center of thirds are\n",
    "    thrds_mask = np.zeros_like(I_h)\n",
    "    thrds_mask[above_first_thrd_rows:below_second_thrd_rows,left_first_thrd_cols:right_second_thrd_cols] = 1\n",
    "    thrds_mask[below_first_thrd_rows:above_second_thrd_rows,right_first_thrd_cols:left_second_thrd_cols] = 0\n",
    "\n",
    "    #HSV and Saliency of the thirds lines\n",
    "    features['Thirds_Hue']      = circstat.mean(I_h[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]*np.pi/180.0)*180.0/np.pi \n",
    "    features['Thirds_Sat']      = np.mean(I_s[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]/255.0)                         \n",
    "    features['Thirds_Value']    = np.mean(I_v[first_thrd_rows:second_thrd_rows,first_thrd_cols:second_thrd_cols]/255.0)                         \n",
    "    features['Thirds_Saliency'] = np.sum(saliencymap[thrds_mask==1])/np.sum(thrds_mask)\n",
    "\n",
    "    #How far is the maximum focal point from the thirds intersections\n",
    "    (maxs_y,maxs_x) = np.where(saliencymap == np.max(saliencymap))\n",
    "    t_rows = [first_thrd_rows,second_thrd_rows]\n",
    "    t_cols = [first_thrd_cols,second_thrd_cols]\n",
    "    thrds_coords = list(itertools.product(t_rows, t_cols))\n",
    "    features['Thirds_To_Focal_Distance']= np.min([np.sqrt(((maxs_x[0] - thrds[1])/np.float(ncols))**2 + ((maxs_y[0] - thrds[0])/np.float(nrows))**2) for thrds in thrds_coords]) / np.sqrt(2)\n",
    "\n",
    "    '''Symmetry Features'''\n",
    "    features['Horizontal_Hue_Sym'],features['Vertical_Hue_Sym'] = CalcSymmetry(I_h)\n",
    "    features['Horizontal_Saturation_Sym'],features['Vertical_Saturation_Sym'] = CalcSymmetry(I_s)\n",
    "    features['Horizontal_Value_Sym'],features['Vertical_Value_Sym'] = CalcSymmetry(I_v)\n",
    "\n",
    "    features['Thirds_Horizontal_Hue_Sym'],features['Thirds_Vertical_Hue_Sym'] = CalcSymmetry(I_h,thrds_mask)\n",
    "    features['Thirds_Horizontal_Saturation_Sym'],features['Thirds_Vertical_Saturation_Sym'] = CalcSymmetry(I_s,thrds_mask)\n",
    "    features['Thirds_Horizontal_Value_Sym'],features['Thirds_Vertical_Value_Sym'] = CalcSymmetry(I_v,thrds_mask)\n",
    "    features['Thirds_Horizontal_Saliency_Sym'],features['Thirds_Vertical_Saliency_Sym'] = CalcSymmetry(saliencymap,thrds_mask)\n",
    "\n",
    "    ''' Image Busyness '''\n",
    "    ret3,thresh = cv2.threshold(cv2.GaussianBlur(I_gray,(5,5),30),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    thresh=cv2.bitwise_not(thresh)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "\n",
    "    cXs=np.array([])\n",
    "    cYs=np.array([])\n",
    "    for c in cnts:\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        if  M[\"m00\"] != 0:\n",
    "            cXs = np.append(cXs,int(M[\"m10\"] / M[\"m00\"]))\n",
    "            cYs = np.append(cYs,int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "    features['Busyness'] = ( (cXs.std()/cXs.mean())**2 + (cYs.std()/cYs.mean())**2)**(1/2)  \n",
    "    features['Number_of_Contours'] = len(cnts)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1427741050720215\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0=time.time()\n",
    "file = '/Users/richardknoche/Desktop/TestImages/Blur/Blurry/Couch4.jpg'\n",
    "features = ExtractFeatures(file)\n",
    "t1=time.time()\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = '/Users/richardknoche/Desktop/TestImages/Blur/Blurry/Couch4.jpg'\n",
    "features = ExtractFeatures(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-72cdff4f3bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features = ExtractFeatures(file)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"from __main__ import *\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features['B_Mean']\n",
    "\n",
    "b,g,r = np.average(np.average(image,axis=0),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.73220864661653"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['R_Mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.73220864661613"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
