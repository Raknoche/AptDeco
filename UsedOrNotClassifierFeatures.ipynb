{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardknoche/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/richardknoche/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import urllib\n",
    "import cv2\n",
    "from ImageFeatures import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://raknoche:localpswd@localhost/AptDeco\")\n",
    "\n",
    "\n",
    "ProductImages = pd.read_sql(\"SELECT * FROM ProductImages\",engine)\n",
    "ProductPopularity = pd.read_sql('SELECT * FROM ProductPopularity;',engine)\n",
    "ProductsTable = pd.read_sql('SELECT * FROM ProductsTable;',engine)\n",
    "ProductsTable.rename(columns={'id':'product_id'}, inplace=True)\n",
    "#UserProductViewHistory = pd.read_sql('SELECT * FROM UserProductViewHistory;',engine)\n",
    "OrderItems = pd.read_sql('SELECT * FROM OrderItems;',engine)\n",
    "#UsersTable = pd.read_sql('SELECT * FROM UsersTable LIMIT 1000;',engine)\n",
    "#WishlistItems = pd.read_sql('SELECT * FROM WishlistItems LIMIT 1000;',engine)\n",
    "#WishlistsTable = pd.read_sql('SELECT * FROM WishlistsTable LIMIT 1000;',engine)\n",
    "#Carts = pd.read_sql('SELECT * FROM Carts LIMIT 1000;',engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Maximum timestamp in the dataset\n",
    "max_timestamp = np.array(OrderItems['created_at'].tolist()+ProductsTable['created_at'].tolist()).max()\n",
    "min_timestamp = ProductsTable.merge(ProductPopularity,how='inner',on='product_id')['created_at'].min()\n",
    "\n",
    "#Add some info about expirations to ProductsTable\n",
    "ProductsTable['HasExpired'] = (ProductsTable['expire_at'] < max_timestamp )\n",
    "\n",
    "#Add info about whether the product sold or not\n",
    "ProductsTable['HasSold'] = ProductsTable.apply(lambda row: row['product_id'] in OrderItems['product_id'].values,axis=1)\n",
    "\n",
    "#Add info about when the items sold\n",
    "temp_df=ProductsTable[ProductsTable['HasSold']==True].merge(OrderItems, how='left', on='product_id')[['product_id','created_at_y']]\n",
    "temp_df.rename(columns={'created_at_y':'sold_at'}, inplace=True)\n",
    "\n",
    "ProductsTable=ProductsTable.merge(temp_df.groupby('product_id').max().reset_index(), how='outer', on='product_id')\n",
    "\n",
    "#Drop user_id is NULL\n",
    "ProductsTable=ProductsTable[ProductsTable['user_id'].notnull()]\n",
    "\n",
    "#Drop products that were created after PopularityTable was\n",
    "ProductsTable=ProductsTable[ProductsTable['created_at'] >= min_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine the ProductTable and ProductPopularity tables\n",
    "count_table=ProductsTable.merge(ProductPopularity, how='outer', on='product_id' )\\\n",
    "    [['product_id','type','count','is_approved','is_published','HasSold','HasExpired','sold_at','expire_at','created_at',\\\n",
    "     'price','original_price','age','width','height','depth','category_id','condition','material_id','color_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get Number of images feature\n",
    "temp=count_table.merge(ProductImages, how = 'outer', on='product_id' )\n",
    "temp = temp.groupby('product_id').count().reset_index()[['product_id','path']]\n",
    "temp.columns=['product_id','Num_Images']\n",
    "count_table = count_table.merge(temp, how='outer', on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a table of how many views each product has, assuming zero if it isn't in ProductPopularity\n",
    "currently_listed = (count_table['is_approved']==True) & (count_table['is_published']==True)\n",
    "already_sold = (count_table['is_approved']==True) & (count_table['HasSold']==True)\n",
    "already_expired = (count_table['is_approved']==True) & (count_table['HasExpired']==True)\n",
    "\n",
    "clean_listings_cut = currently_listed | already_sold | already_expired\n",
    "\n",
    "view_numbers_cut = ((count_table['type']=='view') | (count_table['type'].isnull()))\n",
    "\n",
    "views_table = count_table[ clean_listings_cut  & view_numbers_cut].fillna(0)\n",
    "\n",
    "views_table['Duration'] = [None]*len(views_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get listing lengths\n",
    "sold_cut = views_table['HasSold']==True\n",
    "views_table.ix[sold_cut,'Duration'] = views_table[sold_cut]['sold_at']-views_table[sold_cut]['created_at']\n",
    "\n",
    "expired_cut = (views_table['HasSold']==False) & (views_table['HasExpired']==True)\n",
    "views_table.ix[expired_cut,'Duration'] = views_table[expired_cut]['expire_at']-views_table[expired_cut]['created_at']\n",
    "\n",
    "still_listed_cut = (views_table['HasSold']==False) & (views_table['HasExpired']==False)\n",
    "views_table.ix[still_listed_cut,'Duration'] = max_timestamp-views_table[still_listed_cut]['created_at']\n",
    "\n",
    "#remove listing lengths of zero\n",
    "views_table=views_table[views_table['Duration']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Views per unit time\n",
    "views_table['view_rate']=views_table['count']/views_table['Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a \"WasViewed\" column, and drop uneeded columns\n",
    "cleaned_table = views_table.drop(['type','is_approved','is_published'],axis=1)\n",
    "cleaned_table['WasViewed']=cleaned_table['count']>0\n",
    "\n",
    "#Get the \"main\" image for each product, drop anything that we don't have a picture for\n",
    "main_images = cleaned_table.merge(ProductImages, how='inner', on='product_id')\\\n",
    "    .drop(['id','is_locked','is_visible','s3_path','90_exists','180_exists','270_exists','is_uploaded','description'],axis=1)\n",
    "\n",
    "#Remove the images that don't have actual urls\n",
    "main_images = main_images[ main_images['path'].str.contains(\"https:\")].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_images.sort_index(ascending=False,inplace=True)\n",
    "main_images.reset_index(drop=True,inplace=True)\n",
    "main_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_images=pd.read_csv('AllImages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_images.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75386"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_images.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all of the image feautres\n",
    "for idx in range(len(main_images.dropna()),len(main_images)):\n",
    "    try:\n",
    "        #Image Features\n",
    "        image = url_to_image(main_images.ix[idx,'path'])\n",
    "        features=ExtractFeatures(image)\n",
    "\n",
    "        for key in features.keys():\n",
    "            main_images.loc[idx,key] = features[key]\n",
    "        #except:\n",
    "            #print('Problem Processing Image')\n",
    "\n",
    "        #Save every 2000 images process (~30 minutes)\n",
    "        if (idx % 2000 == 0):\n",
    "            main_images.to_csv('AllImages.csv')\n",
    "    except:\n",
    "        print(\"Problem with grabbing image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-86ab2219b6e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/richardknoche/Python Code/AptDeco/ImageFeatures.py\u001b[0m in \u001b[0;36mExtractFeatures\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#Resize image (should already be 200x200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m800.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "f1 = ExtractFeatures(url_to_image(main_images.ix[0,'path'])\n",
    "f2 = ExtractFeatures(main_images.ix[0,'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_images[main_images['product_id']==1188]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White picture features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_df = main_images[main_images['product_id']==1188].reset_index()\n",
    "for idx in range(len(temp_df)):\n",
    "    resp = urllib.request.urlopen(temp_df.ix[idx,'path'])\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    white_pixels = (image == 255).all(axis=2)\n",
    "    frac_white = len(white_pixels[white_pixels==True])/white_pixels.size\n",
    "    print(temp_df.ix[idx,'path'],frac_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
